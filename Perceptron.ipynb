{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrsowmya/neural-networks/blob/perceptron/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTc3R4PGkrSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perceptron - The 'Hello World' program for the beginners of Neural Network learners\n",
        "\n",
        "# Perceptron is simply an inclusive OR. It takes two inputs and produce one output. It works as follows\n",
        "# A    B     output\n",
        "# 1    0       1\n",
        "# 0    1       1\n",
        "# 1    1       1\n",
        "# 0    0       0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYZljXZksmJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "#learning rate\n",
        "lr = 1\n",
        "bias = 1\n",
        "\n",
        "# Initially random weights are given for the inputs\n",
        "# weigths[0] = input1, weights[1] = input2, weights[2] = bias\n",
        "# random.ranom() - Return the next random floating point number in the range [0.0, 1.0)\n",
        "weights = [random.random(), random.random(), random.random()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVG1t8ESm3Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The simple logic behind this is\n",
        "\n",
        "# The difference between the expected output and the predicted output will be calculated as error\n",
        "# and that will be given to the input layers to update their values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LLJlk5Uux6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_perceptron(input1, input2, output):\n",
        "  outputP = input1*weights[0] + input2*weights[1] + bias*weights[2]\n",
        "  if outputP > 0:\n",
        "    outputP = 1\n",
        "  else:\n",
        "    outputP = 0\n",
        "  error = output - outputP\n",
        "  weights[0] += error*input1*lr\n",
        "  weights[1] += error*input2*lr\n",
        "  weights[2] += error*output*lr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LneXnMLeVp_o",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "# Learning phase\n",
        "\n",
        "for i in range(50):\n",
        "  train_perceptron(1,1,1)\n",
        "  train_perceptron(1,0,1)\n",
        "  train_perceptron(0,1,1)\n",
        "  train_perceptron(0,0,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjsOX0DQWDBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = int(input())\n",
        "y = int(input())\n",
        "output = x*weights[0] + y*weights[1] + bias*weights[2]\n",
        "if output>0:\n",
        "  print(1)\n",
        "else:\n",
        "  print(0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}